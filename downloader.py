import os
import sys
import yt_dlp
import logging
from urllib.request import urlopen
from urllib.parse import urljoin
from html.parser import HTMLParser

# ãƒ­ã‚®ãƒ³ã‚°ã®è¨­å®š
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ãƒ™ãƒ¼ã‚¹ã¨ãªã‚‹ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ«ãƒ€
BASE_DOWNLOAD_DIR = "nerdcore technos"

class LinkParser(HTMLParser):
    def __init__(self, base_url):
        super().__init__()
        self.base_url = base_url
        self.links = []

    def handle_starttag(self, tag, attrs):
        if tag == 'a':
            for name, value in attrs:
                if name == 'href' and (
                    value.endswith('.mp3') or
                    value.endswith('.wav') or
                    value.endswith('.m4a')
                ):
                    full_url = urljoin(self.base_url, value)
                    self.links.append(full_url)

class MusicDownloader:
    # â–¼â–¼â–¼ å¤‰æ›´ç‚¹ â–¼â–¼â–¼
    # åˆæœŸåŒ–æ™‚ã«ã‚µãƒ–ãƒ•ã‚©ãƒ«ãƒ€ã®ãƒ‘ã‚¹ã‚’å—ã‘å–ã‚‹ã‚ˆã†ã«å¤‰æ›´
    def __init__(self, subfolder_path):
        # æŒ‡å®šã•ã‚ŒãŸã‚µãƒ–ãƒ•ã‚©ãƒ«ãƒ€ã‚’å«ã‚ãŸå®Œå…¨ãªãƒ‘ã‚¹ã‚’ä½œæˆ
        full_download_path = os.path.join(BASE_DOWNLOAD_DIR, subfolder_path)
        os.makedirs(full_download_path, exist_ok=True)
        logger.info(f"ğŸ“ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å…ˆãƒ•ã‚©ãƒ«ãƒ€: {full_download_path}")

        self.ydl_opts = {
            'format': 'bestaudio/best',
            # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å…ˆã®ãƒ‘ã‚¹ã‚’æ›´æ–°
            'outtmpl': f'{full_download_path}/%(title)s.%(ext)s',
            # ãƒã‚¹ãƒˆãƒ—ãƒ­ã‚»ãƒƒã‚µã‚’flacã‹ã‚‰mp3ã«å¤‰æ›´
            'postprocessors': [{
                'key': 'FFmpegExtractAudio',
                'preferredcodec': 'mp3',
                'preferredquality': '320', # é«˜éŸ³è³ªãª320kbpsã«è¨­å®š
            }],
            # â–²â–²â–² å¤‰æ›´ç‚¹ â–²â–²â–²
            'extract_flat': False,
            'noplaylist': False,
            'ignoreerrors': False,
            'quiet': False,
            'verbose': True
        }

    def download(self, url, scrape_internal_links=False, source_type='auto_detect'):
        """æŒ‡å®šã•ã‚ŒãŸURLã‹ã‚‰ãƒˆãƒ©ãƒƒã‚¯ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"""
        try:
            logger.info(f"ğŸµ è§£æã¨ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚’é–‹å§‹: {url}")

            if source_type == 'auto_detect':
                source_type = self.detect_source_type(url)

            if source_type in ['soundcloud', 'bandcamp', 'direct_link']:
                if not any(platform in url for platform in ['soundcloud.com', 'bandcamp.com']):
                    logger.error("ğŸš« SoundCloudã¾ãŸã¯Bandcampã®URLã‚’æŒ‡å®šã—ã¦ãã ã•ã„ã€‚")
                    return False

            internal_links = []
            if scrape_internal_links or source_type == 'archive':
                internal_links = self.scrape_internal_links(url)

            self.download_track(url)

            for link in internal_links:
                self.download_track(link)

            return True

        except Exception as e:
            logger.error(f"âš ï¸ äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {str(e)}")
            return False

    def detect_source_type(self, url):
        """URLã‹ã‚‰ã‚½ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—ã‚’è‡ªå‹•æ¤œå‡º"""
        if 'archive.org' in url:
            return 'archive'
        elif 'soundcloud.com' in url:
            return 'soundcloud'
        elif 'bandcamp.com' in url:
            return 'bandcamp'
        else:
            return 'direct_link'

    def scrape_internal_links(self, url):
        """æŒ‡å®šã•ã‚ŒãŸURLã‹ã‚‰å†…éƒ¨ãƒªãƒ³ã‚¯ã‚’ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°"""
        logger.info(f"ğŸ” å†…éƒ¨ãƒªãƒ³ã‚¯ã‚’ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ä¸­: {url}")
        try:
            with urlopen(url) as response:
                html = response.read().decode('utf-8')
        except Exception as e:
            logger.error(f"URLã‚’é–‹ã‘ã¾ã›ã‚“ã§ã—ãŸ: {e}")
            return []

        parser = LinkParser(url)
        parser.feed(html)
        logger.info(f"âœ¨ è¦‹ã¤ã‹ã£ãŸå†…éƒ¨ãƒªãƒ³ã‚¯: {parser.links}")
        return parser.links

    def download_track(self, url):
        """ãƒˆãƒ©ãƒƒã‚¯ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"""
        with yt_dlp.YoutubeDL(self.ydl_opts) as ydl:
            try:
                info = ydl.extract_info(url, download=True)
                logger.info(f"âœ… ãƒˆãƒ©ãƒƒã‚¯ã€Œ{info.get('title', 'Unknown')}ã€ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
            except Exception as e:
                logger.error(f"âš ï¸ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {str(e)}")

def main():
    # â–¼â–¼â–¼ å¤‰æ›´ç‚¹ â–¼â–¼â–¼
    # å¼•æ•°ã®æ•°ã‚’ãƒã‚§ãƒƒã‚¯ (URLxN + scrape_bool + source_type + subfolder)
    if len(sys.argv) < 5:
        logger.error("âŒ å¼•æ•°ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚")
        print("ä½¿ç”¨æ–¹æ³•: python downloader.py <URL1> ... <scrape_bool> <source_type> <subfolder>")
        sys.exit(1)

    # æœ€å¾Œã®å¼•æ•°ã‚’ã‚µãƒ–ãƒ•ã‚©ãƒ«ãƒ€ã¨ã—ã¦å–å¾—
    subfolder = sys.argv[-1]
    source_type = sys.argv[-2]
    scrape_internal_links = sys.argv[-3].lower() == 'true'

    # URLã‚’å–å¾—
    urls = sys.argv[1:-3]

    # MusicDownloaderã«ã‚µãƒ–ãƒ•ã‚©ãƒ«ãƒ€åã‚’æ¸¡ã™
    downloader = MusicDownloader(subfolder_path=subfolder)
    # â–²â–²â–² å¤‰æ›´ç‚¹ â–²â–²â–²

    for url in urls:
        success = downloader.download(url, scrape_internal_links, source_type)
        if not success:
            logger.error(f"âŒ {url} ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")

if __name__ == "__main__":
    main()
